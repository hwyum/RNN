{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REF\n",
    "* https://github.com/dmlc/gluon-nlp/blob/master/docs/api/notes/data_api.rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-20T23:58:57.410465Z",
     "start_time": "2018-07-20T23:58:57.313125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import collections\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score, auc\n",
    "from mxnet import gluon\n",
    "\n",
    "\n",
    "import time, re\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import mxnet as mx\n",
    "import spacy\n",
    "os.environ['MXNET_ENGINE_TYPE'] = 'NaiveEngine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Data preparation\n",
    "* Input data shape::$ (batch \\times word \\times vocab )$ \n",
    "* Split data: training & validation\n",
    "* Create data iterator for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-20T23:59:02.851826Z",
     "start_time": "2018-07-20T23:59:02.847817Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 20\n",
    "MAX_VOCAB = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T00:01:54.877372Z",
     "start_time": "2018-07-20T23:59:04.343517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count words and build vocab...\n",
      "Prepare data...\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "word_freq = collections.Counter()\n",
    "max_len = 0\n",
    "num_rec = 0\n",
    "print('Count words and build vocab...')\n",
    "with open('../data/umich-sentiment-train.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        _lab, _sen = line.decode('utf8').strip().split('\\t')\n",
    "        words = [token.lemma_ for token in nlp(_sen) if token.is_alpha] # Stop word제거 안한 상태 \n",
    "        # 제거를 위해 [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "        if len(words) > max_len:\n",
    "            max_len = len(words)\n",
    "        for word in words:\n",
    "            word_freq[word] += 1\n",
    "        num_rec += 1\n",
    "\n",
    "# most_common output -> list\n",
    "word2idx = {x[0]: i+2 for i, x in enumerate(word_freq.most_common(MAX_VOCAB - 2))}\n",
    "word2idx ['PAD'] = 0\n",
    "word2idx['UNK'] = 1\n",
    "\n",
    "idx2word= {i:v for v, i in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "print('Prepare data...')\n",
    "y = []\n",
    "x = []\n",
    "origin_txt = []\n",
    "with open('../data/umich-sentiment-train.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        _label, _sen = line.decode('utf8').strip().split('\\t')\n",
    "        origin_txt.append(_sen)\n",
    "        y.append(int(_label))\n",
    "        words = [token.lemma_ for token in nlp(_sen) if token.is_alpha] # Stop word제거 안한 상태\n",
    "        words = [x for x in words if x != '-PRON-'] # '-PRON-' 제거\n",
    "        _seq = []\n",
    "        for word in words:\n",
    "            if word in word2idx.keys():\n",
    "                _seq.append(word2idx[word])\n",
    "            else:\n",
    "                _seq.append(word2idx['UNK'])\n",
    "        if len(_seq) < MAX_SENTENCE_LENGTH:\n",
    "            _seq.extend([0] * ((MAX_SENTENCE_LENGTH) - len(_seq)))\n",
    "        else:\n",
    "            _seq = _seq[:MAX_SENTENCE_LENGTH]\n",
    "        x.append(_seq)\n",
    "\n",
    "pd.DataFrame(y, columns = ['yn']).reset_index().groupby('yn').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T00:06:13.110042Z",
     "start_time": "2018-07-21T00:06:13.001642Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data process - tr/va split and define iterator\n",
    "\n",
    "tr_idx = np.random.choice(range(len(x)), int(len(x) * .8))\n",
    "va_idx = [x for x in range(len(x)) if x not in tr_idx]\n",
    "\n",
    "tr_x = [x[i] for i in tr_idx]\n",
    "tr_y = [y[i] for i in tr_idx]\n",
    "va_x = [x[i] for i in va_idx]\n",
    "va_y = [y[i] for i in va_idx]\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_data = mx.io.NDArrayIter(data=[tr_x, tr_y], batch_size=batch_size, shuffle = False)\n",
    "valid_data = mx.io.NDArrayIter(data=[va_x, va_y], batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T00:06:16.350981Z",
     "start_time": "2018-07-21T00:06:16.347552Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn, rnn\n",
    "import mxnet as mx\n",
    "context = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T00:06:19.761524Z",
     "start_time": "2018-07-21T00:06:19.757185Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = .0002\n",
    "log_interval = 100\n",
    "emb_dim = 100 # Emb dim\n",
    "hidden_dim = 30 # Hidden dim for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T00:07:50.840778Z",
     "start_time": "2018-07-21T00:07:50.829725Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sentence_Representation(nn.Block):\n",
    "    def __init__(self, EMB_DIM, HIDDEN_DIM, VOCAB_SIZE, dropout = .2, **kwargs):\n",
    "        super(Sentence_Representation, self).__init__(**kwargs)\n",
    "        self.VOCAB_SIZE = VOCAB_SIZE\n",
    "        self.EMB_DIM = EMB_DIM\n",
    "        self.HIDDEN_DIM = HIDDEN_DIM\n",
    "        with self.name_scope():\n",
    "            self.hidden = []\n",
    "            self.embed = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "            self.lstm = rnn.LSTM(HIDDEN_DIM // 2, num_layers= 2, dropout = dropout, input_size = EMB_DIM, bidirectional=True)\n",
    "            self.drop = nn.Dropout(.2)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        #print('x = {}'.format(x))\n",
    "        embeds = self.embed(x) # batch * time step * embedding: NTC\n",
    "        lstm_out, self.hidden = self.lstm(nd.transpose(embeds, (1, 0, 2)), hidden) #TNC로 변환\n",
    "        _hid = [nd.transpose(x, (1, 0, 2)) for x in self.hidden]\n",
    "        print('_hid len = {}'.format(len(_hid)))\n",
    "        # Concatenate depreciated. use concat. input list of tensors\n",
    "        _hidden = nd.concat(*_hid)\n",
    "        return lstm_out, self.hidden\n",
    "\n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.lstm.begin_state(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T00:17:42.390954Z",
     "start_time": "2018-07-21T00:17:42.383638Z"
    }
   },
   "outputs": [],
   "source": [
    "class SA_Classifier(nn.Block):\n",
    "    def __init__(self, sen_rep, classifier, batch_size, context, **kwargs):\n",
    "        super(SA_Classifier, self).__init__(**kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        self.context = context\n",
    "        with self.name_scope():\n",
    "            self.sen_rep = sen_rep\n",
    "            self.classifier = classifier\n",
    "            \n",
    "    def forward(self, x):\n",
    "        hidden = self.sen_rep.begin_state(func = mx.nd.zeros, batch_size = self.batch_size, ctx = self.context)\n",
    "        print('hidden shape = {}'.format([x.shape for x in hidden]))\n",
    "        #_x, _ = self.sen_rep(x, hidden)\n",
    "        _, _x = self.sen_rep(x, hidden) # Use the last hidden step\n",
    "        print('x shape = {}'.format(_x[0].shape))\n",
    "        x = nd.reshape(x, (-1,))\n",
    "        print('xaa = {}'.format(_x[1].shape))\n",
    "        x = self.classifier(x)\n",
    "        return x           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T00:17:43.256604Z",
     "start_time": "2018-07-21T00:17:43.176393Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20)\n",
      "hidden shape = [(4, 2, 15), (4, 2, 15)]\n",
      "_hid len = 2\n",
      "x shape = (4, 2, 15)\n",
      "xaa shape = (4, 2, 15)\n",
      "xaa = (4, 2, 15)\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Shape inconsistent, Provided = [16,30], inferred shape=(16,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f911134d98bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSA_Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#sa.collect_params().initialize(mx.init.Xavier(), ctx = context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-d829c9910488>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xaa = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x, weight, bias)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         act = F.FullyConnected(x, weight, bias, no_bias=bias is None, num_hidden=self._units,\n\u001b[0;32m--> 206\u001b[0;31m                                flatten=self._flatten, name='fwd')\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mFullyConnected\u001b[0;34m(data, weight, bias, num_hidden, no_bias, flatten, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Shape inconsistent, Provided = [16,30], inferred shape=(16,1)"
     ]
    }
   ],
   "source": [
    "z = nd.array([np.arange(MAX_SENTENCE_LENGTH), np.arange(MAX_SENTENCE_LENGTH) + 10], ctx= context)\n",
    "print(z.shape)\n",
    "sen_rep = Sentence_Representation(emb_dim, hidden_dim, MAX_VOCAB)\n",
    "sen_rep.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "sa = SA_Classifier(sen_rep, classifier, 2, context)\n",
    "#sa.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "print(sa(z))\n",
    "trainer = gluon.Trainer(sa.collect_params(), 'adam', {'learning_rate': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_rep = Sentence_Representation(emb_dim, hidden_dim, MAX_VOCAB)\n",
    "sen_rep.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "\n",
    "classifier = nn.Sequential()\n",
    "classifier.add(nn.Dense(16, activation = 'relu'))\n",
    "classifier.add(nn.Dense(8, activation = 'relu'))\n",
    "classifier.add(nn.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T04:15:45.120579Z",
     "start_time": "2018-07-04T04:15:44.964074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_embedding0_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l0_i2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l0_h2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l0_i2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l0_h2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r0_i2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r0_h2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r0_i2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r0_h2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l1_i2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l1_h2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l1_i2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_l1_h2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r1_i2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r1_h2h_weight is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r1_i2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/gluon/parameter.py:320: UserWarning: Parameter sentence_representation1_lstm0_r1_h2h_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  \"Set force_reinit=True to re-initialize.\"%self.name)\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 50 # Emb dim\n",
    "hidden_dim = 30 # Hidden dim for LSTM\n",
    "sa = SA_Classifier(sen_rep, classifier,  batch_size, context)\n",
    "sa.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "loss = gluon.loss.SigmoidBCELoss()\n",
    "trainer = gluon.Trainer(sa.collect_params(), 'adam', {'learning_rate': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, dataIterator, context):\n",
    "    dataIterator.reset()\n",
    "    loss = gluon.loss.SigmoidBCELoss()\n",
    "    total_L = 0.0\n",
    "    total_sample_num = 0\n",
    "    total_correct_num = 0\n",
    "    start_log_interval_time = time.time()\n",
    "    for i, batch in enumerate(dataIterator):\n",
    "        data =  batch.data[0].as_in_context(context)\n",
    "        label = batch.data[1].as_in_context(context)\n",
    "        output = net(data)\n",
    "        L = loss(output, label)\n",
    "        pred = (output > 0.5).reshape((-1,))\n",
    "        #print('cor = {}'.format(pred == label))\n",
    "        total_L += L.sum().asscalar()\n",
    "        total_sample_num += len(label)\n",
    "        total_correct_num += (pred == label).sum().asscalar()\n",
    "        #print('total_correct_num = {}, total_correct_num = {}'.format(total_correct_num, total_sample_num))\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            print('[Batch {}/{}] elapsed {:.2f} s'.format(\n",
    "                i + 1, dataIterator.num_data//dataIterator.batch_size,\n",
    "                time.time() - start_log_interval_time))\n",
    "            start_log_interval_time = time.time()\n",
    "    avg_L = total_L / float(total_sample_num)\n",
    "    acc = total_correct_num / float(total_sample_num)\n",
    "    return avg_L, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9381bdafa374dce9b772d7e01dd021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/354] elapsed 2.36 s,                     avg loss 0.012871, throughput 0.68K wps\n",
      "[Epoch 0 Batch 200/354] elapsed 2.28 s,                     avg loss 0.003748, throughput 0.70K wps\n",
      "[Epoch 0 Batch 300/354] elapsed 2.28 s,                     avg loss 0.001471, throughput 0.70K wps\n",
      "[Batch 100/199] elapsed 1.33 s\n",
      "[Batch 200/199] elapsed 1.33 s\n",
      "[Epoch 0] train avg loss 0.005285, valid acc 0.98,         valid avg loss 0.068408, throughput 0.70K wps\n",
      "[Epoch 1 Batch 100/354] elapsed 2.28 s,                     avg loss 0.000699, throughput 0.70K wps\n",
      "[Epoch 1 Batch 200/354] elapsed 2.32 s,                     avg loss 0.000474, throughput 0.69K wps\n",
      "[Epoch 1 Batch 300/354] elapsed 2.27 s,                     avg loss 0.000329, throughput 0.70K wps\n",
      "[Batch 100/199] elapsed 1.33 s\n",
      "[Batch 200/199] elapsed 1.33 s\n",
      "[Epoch 1] train avg loss 0.000528, valid acc 0.98,         valid avg loss 0.071186, throughput 0.70K wps\n",
      "[Epoch 2 Batch 100/354] elapsed 2.30 s,                     avg loss 0.000219, throughput 0.69K wps\n",
      "[Epoch 2 Batch 200/354] elapsed 2.28 s,                     avg loss 0.000447, throughput 0.70K wps\n",
      "[Epoch 2 Batch 300/354] elapsed 2.29 s,                     avg loss 0.000196, throughput 0.70K wps\n",
      "[Batch 100/199] elapsed 1.33 s\n",
      "[Batch 200/199] elapsed 1.34 s\n",
      "[Epoch 2] train avg loss 0.000273, valid acc 0.98,         valid avg loss 0.055328, throughput 0.70K wps\n",
      "[Epoch 3 Batch 100/354] elapsed 2.28 s,                     avg loss 0.000112, throughput 0.70K wps\n",
      "[Epoch 3 Batch 200/354] elapsed 2.28 s,                     avg loss 0.005306, throughput 0.70K wps\n",
      "[Epoch 3 Batch 300/354] elapsed 2.28 s,                     avg loss 0.003003, throughput 0.70K wps\n",
      "[Batch 100/199] elapsed 1.34 s\n",
      "[Batch 200/199] elapsed 1.34 s\n",
      "[Epoch 3] train avg loss 0.002445, valid acc 0.98,         valid avg loss 0.089481, throughput 0.70K wps\n",
      "[Epoch 4 Batch 100/354] elapsed 2.28 s,                     avg loss 0.000470, throughput 0.70K wps\n",
      "[Epoch 4 Batch 200/354] elapsed 2.28 s,                     avg loss 0.000327, throughput 0.70K wps\n",
      "[Epoch 4 Batch 300/354] elapsed 2.28 s,                     avg loss 0.000084, throughput 0.70K wps\n",
      "[Batch 100/199] elapsed 1.33 s\n",
      "[Batch 200/199] elapsed 1.34 s\n",
      "[Epoch 4] train avg loss 0.000293, valid acc 0.98,         valid avg loss 0.098095, throughput 0.70K wps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 5\n",
    "for epoch in tqdm_notebook(range(n_epoch), desc = 'epoch'):\n",
    "    ## Training\n",
    "    train_data.reset()\n",
    "    # Epoch training stats\n",
    "    start_epoch_time = time.time()\n",
    "    epoch_L = 0.0\n",
    "    epoch_sent_num = 0\n",
    "    epoch_wc = 0\n",
    "    # Log interval training stats\n",
    "    start_log_interval_time = time.time()\n",
    "    log_interval_wc = 0\n",
    "    log_interval_sent_num = 0\n",
    "    log_interval_L = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(train_data):\n",
    "        _data = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        L = 0\n",
    "        wc = len(_data)\n",
    "        log_interval_wc += wc\n",
    "        epoch_wc += wc\n",
    "        log_interval_sent_num += _data.shape[1]\n",
    "        epoch_sent_num += _data.shape[1]\n",
    "        with autograd.record():\n",
    "            _out = sa(_data)\n",
    "            L = L + loss(_out, _label).mean().as_in_context(context)\n",
    "        L.backward()\n",
    "        trainer.step(_data.shape[0])\n",
    "        log_interval_L += L.asscalar()\n",
    "        epoch_L += L.asscalar()\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            tqdm.write('[Epoch {} Batch {}/{}] elapsed {:.2f} s, \\\n",
    "                    avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
    "                    epoch, i + 1, train_data.num_data//train_data.batch_size,\n",
    "                    time.time() - start_log_interval_time,\n",
    "                    log_interval_L / log_interval_sent_num,\n",
    "                    log_interval_wc / 1000 / (time.time() - start_log_interval_time)))\n",
    "            # Clear log interval training stats\n",
    "            start_log_interval_time = time.time()\n",
    "            log_interval_wc = 0\n",
    "            log_interval_sent_num = 0\n",
    "            log_interval_L = 0\n",
    "    end_epoch_time = time.time()\n",
    "    test_avg_L, test_acc = evaluate(sa, valid_data, context)\n",
    "    tqdm.write('[Epoch {}] train avg loss {:.6f}, valid acc {:.2f}, \\\n",
    "        valid avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
    "        epoch, epoch_L / epoch_sent_num,\n",
    "        test_acc, test_avg_L, epoch_wc / 1000 /\n",
    "        (end_epoch_time - start_epoch_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>pred_sa</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anyway, thats why I love \" Brokeback Mountain.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combining the opinion / review from Gary and G...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we're gonna like watch Mission Impossible or H...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Da Vinci Code sucked big time.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am going to start reading the Harry Potter s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am going to start reading the Harry Potter s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Always knows what I want, not guy crazy, hates...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I loved this mission impossible scenario.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I liked the first \" Mission Impossible.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brokeback Mountain is fucking horrible..</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt  pred_sa  label\n",
       "0     Anyway, thats why I love \" Brokeback Mountain.      1.0      1\n",
       "1  Combining the opinion / review from Gary and G...      0.0      0\n",
       "2  we're gonna like watch Mission Impossible or H...      1.0      1\n",
       "3                 The Da Vinci Code sucked big time.      0.0      0\n",
       "4  I am going to start reading the Harry Potter s...      1.0      1\n",
       "5  I am going to start reading the Harry Potter s...      1.0      1\n",
       "6  Always knows what I want, not guy crazy, hates...      0.0      0\n",
       "7          I loved this mission impossible scenario.      0.0      1\n",
       "8            I liked the first \" Mission Impossible.      1.0      1\n",
       "9           Brokeback Mountain is fucking horrible..      0.0      0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# We need to specify batch_size explicitly becuase we need that in reshaping\n",
    "idx = np.random.choice(len(va_idx), batch_size)\n",
    "va_txt = [origin_txt[_idx] for _idx in va_idx]\n",
    "va_txt = [va_txt[j] for j in idx]\n",
    "va_txt = pd.DataFrame(va_txt, columns = ['txt'])\n",
    "y_pred_sa, A = rn(nd.array([va_x[i] for i in idx], ctx = context))\n",
    "pred_sa = [nd.round(val).asnumpy() for val in nd.sigmoid(y_pred_sa)] \n",
    "pred_sa_pd = pd.DataFrame(pred_sa, columns  = ['pred_sa'])\n",
    "label_pd = pd.DataFrame([va_y[j] for j in idx], columns = ['label'])\n",
    "result = pd.concat([va_txt, pred_sa_pd, label_pd], axis = 1)\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>pred_sa</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I loved this mission impossible scenario.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         txt  pred_sa  label\n",
       "7  I loved this mission impossible scenario.      0.0      1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['pred_sa'] != result['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention(_att, _sentence, sentence_id):\n",
    "    x = _sentence[sentence_id]\n",
    "    _att = _att[sentence_id].asnumpy()\n",
    "    word = []\n",
    "    w_idx = []\n",
    "    for token in x:\n",
    "        #print(token)\n",
    "        _word = idx2word[token]\n",
    "        word.append(_word)\n",
    "    att = pd.DataFrame(_att, index = word, columns = word)\n",
    "    print(word)\n",
    "    w_idx = [x for x in word if x is not 'PAD']\n",
    "    print(w_idx)\n",
    "    res = att.loc[w_idx][w_idx]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'hate', 'harry', 'potter', '.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['i', 'hate', 'harry', 'potter', '.']\n",
      "label: 0, predicted: 0.0\n",
      "['i', 'hate', 'harry', 'potter', '.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['i', 'hate', 'harry', 'potter', '.']\n",
      "label: 0, predicted: 0.0\n",
      "['i', 'hate', 'harry', 'potter', '.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['i', 'hate', 'harry', 'potter', '.']\n",
      "label: 0, predicted: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHzhJREFUeJzt3X9UVHX+P/DnMASK/BCzxh8QGViWUDtmLbjb7nGIMAlwEkLORlm6FXUOsHqgdrdQybKSFtlOrnr8kXosWxIkIUWBLWuXtk8nXMofBSnxIxwURwM0Zph5f//w25xGcrjADMO9PB+de0535j3v+3pX5+Wr933f91UJIQSIiEh2PNwdABERDQ4TOBGRTDGBExHJFBM4EZFMMYETEcmUp6svcKnkFVdfYtip74pzdwhEiuQVFDHkPsxnT0pue83Em4Z8PXdiBU5EJFMur8CJiIaV1eLuCIYNEzgRKYul190RDBsmcCJSFCGs7g5h2DCBE5GyWJnAiYjkiRU4EZFM8SYmEZFMsQInIpInwVUoREQyxZuYREQyxSkUIiKZ4k1MIiKZYgVORCRTvIlJRCRTo+gmJreTJSJFEcIi+ejP4cOHERsbi5iYGGzatKnP9yaTCVlZWYiJiUFycjJaWloAAEajEWlpadBqtcjLy7P7zQcffID4+HjExcVh7dq1ts+Li4sRGRmJxMREJCYmoqioqN/4mMCJSFmEVfrhgMViQV5eHjZv3ozy8nKUlZWhoaHBrk1RURH8/f1x6NAhLF68GPn5+QAAb29vZGZmIicnx6690WjEa6+9hu3bt6O8vBxnz55FTU2N7fv58+ejtLQUpaWlSE5O7neoTOBEpCxWq/TDgbq6OoSEhCA4OBheXl6Ii4tDVVWVXZvq6mro9XoAQGxsLGpqaiCEgI+PD2bPng1vb2+79s3NzQgJCcGECRMAAFFRUaioqBj0UJnAiUhZnFSBGwwGTJo0yXau0WhgMBj6tJk8eTIAwNPTE35+fjAajVftMyQkBKdOnUJLSwt6e3tRVVWF06dP274/ePAg4uPjkZGRgba2tn6HypuYRKQsFrO7I7iqgIAArFy5En/605/g4eEBrVaLpqYmAMDcuXPxwAMPwMvLC7t378azzz6LHTt2OOyPCZyIlMVJq1A0Go1ddWwwGKDRaPq0aWtrw6RJk9Db24vOzk4EBgY67Fen00Gn0wEA3n33XXh4XJ4I+fnvkpOT7W5wXo3DKZTU1FQAgFarxaxZs2zHT+dERCOOk6ZQIiIi0NjYiObmZphMJpSXl9sS7090Oh1KSkoAABUVFYiMjIRKpXLYb0dHBwDgwoULePvtt203K9vb221tqqurERoa2u9QHVbg77zzDgCgtra2346IiEYEJ1Xgnp6eyM3NxdKlS2GxWLBw4UJMnz4dhYWFCA8PR3R0NJKSkpCdnY2YmBgEBASgoKDA9nudToeuri6YzWZUVlZi69atCAsLw0svvYQTJ04AAJ555hlMmzYNALBz505UV1dDrVYjICAAa9as6TdGlRBCOGW0V3Gp5BVXdu8W6rvi3B0CkSJ5BUUMuY8fP94pue2Ye9KGfD134hw4ESmKGME3MZ2NCZyIlIWbWRERydQo2guFCZyIlIUVOBGRTLECJyKSKVbgREQy1csXOhARyRMrcCIimeIcOBGRTLECJyKSKVbgREQyxQqciEimuAqFiEimXLvB6ojCBE5EysI5cCIimWICJyKSKd7EJCKSKYvF3REMG5cncL+UN1x9iWF38SRfqUY0YnEKhYhIppjAiYhkinPgRETyJKxcB05EJE+cQiEikimuQiEikilW4EREMsUETkQkU9zMiohIpliBExHJFJcREhHJFFehEBHJk+AUChGRTI2iKRQPdwdARORUwir96Mfhw4cRGxuLmJgYbNq0qc/3JpMJWVlZiImJQXJyMlpaWgAARqMRaWlp0Gq1yMvLs/tNWVkZ4uPjER8fjyVLluDcuXMAgPPnz+Oxxx7Dfffdh8ceewwXLlzoNz4mcCJSFquQfjhgsViQl5eHzZs3o7y8HGVlZWhoaLBrU1RUBH9/fxw6dAiLFy9Gfn4+AMDb2xuZmZnIycmxa9/b24uXXnoJ27dvx759+3DLLbdg165dAIBNmzYhKioKBw8eRFRU1C/+gXElJnAiUpZei/TDgbq6OoSEhCA4OBheXl6Ii4tDVVWVXZvq6mro9XoAQGxsLGpqaiCEgI+PD2bPng1vb2+79kIICCFw6dIlCCHQ1dWF66+/HgBQVVWFBQsWAAAWLFiAysrKfofKBE5EyuKkKRSDwYBJkybZzjUaDQwGQ582kydPBgB4enrCz88PRqPxqn1ec801WLlyJeLj43HPPffg22+/RVJSEgCgo6PDlsyvu+46dHR09DtUJnAiUhYnTaG4gtlsxjvvvIO9e/fi448/xi233IKNGzf2aadSqaBSqfrtjwmciBRFWK2SD0c0Gg1Onz5tOzcYDNBoNH3atLW1Abg8v93Z2YnAwMCr9nn8+HEAwA033ACVSoX7778ftbW1AIBrr70W7e3tAID29nZMmDCh37EygRORsjipAo+IiEBjYyOam5thMplQXl4OnU5n10an06GkpAQAUFFRgcjISIeVs0ajwbfffmtbefLvf/8boaGhtr727t0LANi7dy+io6P7HapKCNfu/OLpNdWV3bvFxZMH3B0CkSJ5BUUMuY+ubL3ktr5rSxx+/9FHH+Hll1+GxWLBwoULkZ6ejsLCQoSHhyM6Oho9PT3Izs7G8ePHERAQgIKCAgQHBwO4nJC7urpgNpvh5+eHrVu3IiwsDO+88w527NgBT09PTJ06FWvWrEFgYCCMRiOysrLQ1taGKVOmYN26dRg/frzD+CQl8FOnTmHlypXo6OhAWVkZTpw4gerqajz99NP9/gNiAiciqZySwJclSG7r+7f3h3w9d5I0hfLCCy9g+fLl8PS8/ODmjBkz8MEHH7g0MCKiwRBWIfmQO0mP0l+6dAm333673WdqtdolARERDYkCErNUkhJ4YGAgmpqabJPzBw4cwHXXXefSwIiIBoWbWdlbsWIFXnjhBZw8eRL33HMPgoKCbI+MEhGNKKzA+3rrrbdw8eJFWK1W+Pr6orm52ZVxERENzihK4JJuYmZkZAAAfHx84OvrCwDIzMx0XVRERIMkLFbJh9w5rMC//fZbNDQ0oLOzEwcPHrR93tXVhZ6eHpcHR0Q0YKOoAneYwE+dOoUPP/wQnZ2d+Ne//mX7fNy4cXjxxRddHhwR0UApYXmgVA4T+L333ot7770XtbW10Gq1wxUTEdHgMYHbu+2227Br1y7U19fbTZ2sWbPGZYEREQ2K/Ke2JZN0EzM7OxtnzpzBJ598grvvvhsGgwHjxo1zdWxERAMmeq2SD7mTlMCbmpqQlZWFsWPHQq/XY+PGjairq3N1bEREA2cdwCFzkqZQftoDxd/fH9988w0mTpwo6W0RRETDjTcxr5CSkoILFy4gKysL6enpuHjxIteBE9HIpIDKWipJCTwxMREVFRVobW21vcDz7NmzLg2MiGgwWIFfIT09HX5+fpg5cya8vLxcHRMR0eCxArdnMBiwZcsWV8dCRDRkotfdEQwfSatQtFotvv76a1fHQkQ0ZMIq/ZA7hxV4fHw8AMBisaC4uBhBQUF2Uyj79u1zbXRERAOlgMQslcMEvmHDhuGKg4jIKZRQWUvlMIFPnaq8FxITkbIxgTvRpe8/dvUlhp34sdvdIRDRVQiLyt0hDBuXJ3AiouHECpyISKaElRU4EZEssQInIpIpIViBExHJEitwIiKZsnIVChGRPPEmJhGRTDGBExHJlBg924EzgRORsoymClzSdrJERHIhhEry0Z/Dhw8jNjYWMTEx2LRpU5/vTSYTsrKyEBMTg+TkZLS0tAAAjEYj0tLSoNVqkZeX1+c3L7zwAmJjYzFv3jxUVFQAAIqLixEZGYnExEQkJiaiqKio3/hYgRORolictArFYrEgLy8P27Ztg0ajQVJSEnQ6HcLCwmxtioqK4O/vj0OHDqG8vBz5+flYt24dvL29kZmZifr6etTX19v1u2HDBkyYMAEVFRWwWq04f/687bv58+cjNzdXcoyswIlIUZxVgdfV1SEkJATBwcHw8vJCXFwcqqqq7NpUV1fb3hMcGxuLmpoaCCHg4+OD2bNnw9vbu0+/e/bswZNPPgkA8PDwwIQJEwY9ViZwIlIUYVVJPhwxGAyYNGmS7Vyj0cBgMPRpM3nyZACAp6cn/Pz8YDQar9rnDz/8AAAoLCyEXq9HRkaG3QviDx48iPj4eGRkZKCtra3fsTKBE5GiCCH9GG69vb04ffo0tFotSkpKoNVq8eqrrwIA5s6di+rqauzbtw9z5szBs88+229/TOBEpCjOqsA1Gg1Onz5tOzcYDNBoNH3a/FQp9/b2orOzE4GBgVftMzAwEGPHjsV9990HAJg3bx6OHTtm++6nV1YmJyfj6NGj/Y6VCZyIFMVi9ZB8OBIREYHGxkY0NzfDZDKhvLwcOp3Oro1Op0NJSQkAoKKiApGRkVCprv4Hg0qlwty5c/Hf//4XAFBTU4PQ0FAAQHt7u61ddXW17XNHVEK49n8kzGdPurJ7t+AbeYhcwysoYsh91N0YL7nt7Y2OX8z+0Ucf4eWXX4bFYsHChQuRnp6OwsJChIeHIzo6Gj09PcjOzsbx48cREBCAgoICBAcHA7ic3Lu6umA2m+Hn54etW7ciLCwMra2tyMnJwQ8//IAJEyZgzZo1mDJlCl5//XVUV1dDrVYjICAAK1eu7DeJM4EPAhM4kWs4I4EfCUmQ3PZX370/5Ou5E9eBE5GijKb9wCXNgX/99deujoOIyClG8ioUZ5NUga9atQomkwl6vR4JCQnw8/NzdVxERINiHUUVuKQE/vbbb6OxsRF79uzBgw8+iNtvvx0PPvggfvOb37g6PiKiAelvdYmSSJ4Dv/HGG5GVlYXw8HCsXr0ax44dgxACy5Yts61pJCJyNwXMjEgmKYGfOHECxcXF+OijjzBnzhxs2LABM2fOhMFgwKJFi5jAiWjE4BTKFVavXo2kpCQsW7YMY8aMsX2u0WiQmZnpsuCIiAZqNK1C6TeBWywWaDQaLFiw4Be/v9rnRETuMIpeSt9/Aler1Whra4PJZLI9p09ENFIJsAK3ExQUhNTUVOh0Ovj4+Ng+f+yxx1wWGBHRYPRyCsXeDTfcgBtuuAFCCHR38zFyIhq5WIH/jMViQXd3t6S9aYmI3I1z4D+jVqvxxRdfDEcsRERDxgr8CjNmzMBTTz2FefPm2c2Bc/03EY00rMCvYDKZEBgYaNuE/CdM4EQ00lhYgdtbs2aNq+MgInKKft6UpiiSEnhPTw/ee+891NfXo6enx/Y5EzsRjTTWUVSBS9q2Kzs7G2fOnMEnn3yCu+++GwaDAePGjXN1bEREAyYGcMidpATe1NSErKwsjB07Fnq9Hhs3bkRdXZ2rYyMiGjDrAA65kzSF4ul5uZm/vz+++eYbTJw4ER0dHS4NjIhoMKwO3gqvNJISeEpKCi5cuICsrCykp6fj4sWL3IWQiEYki7sDGEaSEnhiYiIqKirQ2toKvV4PADh79qxLAyMiGgyuQrlCeno6/Pz8MHPmTO5ISEQj2mhahSIpgRsMBmzZssXVsRARDZkSVpdIJWkVilarxddff+3qWIiIhsyqkn7IncMKPD4+HsDlHQmLi4sRFBRkN4Wyb98+10ZHRDRASlgeKJXDBL5hw4bhioOIyCksCqispXKYwKdOnTpccRAROQUrcCIimWICJyKSqVH0SkwmcCJSFlbgREQyNZoepZe0DpyISC6cuQ788OHDiI2NRUxMDDZt2tTne5PJhKysLMTExCA5ORktLS0AAKPRiLS0NGi1WuTl5dn9Ji0tDbGxsUhMTERiYqJtY8Cr9eUIEzgRKYqztpO1WCzIy8vD5s2bUV5ejrKyMjQ0NNi1KSoqgr+/Pw4dOoTFixcjPz8fAODt7Y3MzEzk5OT8Yt/5+fkoLS1FaWkprr32Wod9OcIETkSK4qwEXldXh5CQEAQHB8PLywtxcXGoqqqya1NdXW3b4C82NhY1NTUQQsDHxwezZ8+Gt7e35Liv1pcjTOBEpCjOeiOPwWDApEmTbOcajQYGg6FPm8mTJwO4/N4EPz8/GI3GfmP8y1/+gsTERLz55pu2JD2YvngTk4gUZaTvcZKfnw+NRoOuri5kZGSgtLQUCxYsGFRfrMCJSFEsAzgc0Wg0OH36tO3cYDBAo9H0adPW1gYA6O3tRWdnJwIDA/vtFwB8fX3xwAMP2F5POZi+mMCJSFGsEJIPRyIiItDY2Ijm5maYTCaUl5dDp9PZtdHpdCgpKQEAVFRUIDIyEioHr3Tr7e3FuXPnAABmsxkffvghpk+fPqi+AE6hEJHCOOtBHk9PT+Tm5mLp0qWwWCxYuHAhpk+fjsLCQoSHhyM6OhpJSUnIzs5GTEwMAgICUFBQYPu9TqdDV1cXzGYzKisrsXXrVkyZMgVLly6F2WyG1WpFVFQUHnroIQBw2NfVqER/tzmHyHz2pCu7dwvxY7e7QyBSJK+giCH3kRfyB8ltc7/bNeTruRMrcCJSFD5KT0QkU72q0fNSNSZwIlKU0ZO+JaxCsVqt+OKLL4YjFiKiIXPWk5hy0G8C9/Dw6LMZCxHRSOWsZYRyIGkdeFRUFCoqKvp9Lp+IyN2c9Si9HEiaA9+9eze2bdsGtVoNb29vCCGgUqk4tUJEI44SpkakkpTAa2trXR0HEZFTWBRRW0sjaQpFCIHS0lK8+eabAIC2tjbb8/tERCMJb2JeYeXKlThy5AjKysoAAD4+Pli1apVLAyMiGgwxgL/kTlICr6urw4oVK2ybkwcEBMBsNrs0MCKiwRhNFbikOXBPT09YLBbbzljnzp2Dhwc3MiSikUcJywOlkpTA09LS8Mwzz6CjowMFBQU4cOAAMjMzXR0bEdGAjZ70LTGBJyQkYObMmfj0008hhMD69esRGhrq6tiIiAasdxSlcEnzINnZ2QgNDcUf/vAHPPzwwwgNDUV2drarYyMiGrDRdBNTUgXe0NBgd26xWHD06FGXBERENBRKuDkplcMEvnHjRmzYsAE9PT2YNWsWgMtrwr28vJCcnDwsARIRDYQSKmupJL2R5/XXX8fy5csHdQG+kYeIpHLGG3kevXGh5LbbG/cM+XruJHkd+JUeffRRpwdDRDRUFiEkH3LncAqlp6cHFy9ehNFoxIULF2y7EXZ1dcFgMAxLgEREA8F14P/f7t27sX37drS3t0Ov19s+9/X1xcMPP+zy4IiIBopz4FfYuXMn0tLSBnUBzoETkVTOmANPCVkgue273+0d8vXcSdIywpSUFOzYsQOff/45AODuu+9GSkoKrrnmGpcGR0Q0UKNpCkXSTcxVq1bh6NGjSE1NRWpqKo4ePYqVK1e6ODQiooHjgzxX+PLLL/H+++/bzqOiopCQkOCyoIiIBksJq0ukklSBq9VqNDU12c6bm5uhVqtdFhQR0WCNppcaS6rAc3Jy8MgjjyA4OBgA0NraipdfftmlgRERDcZoepReUgU+a9YspKSkQKVSISAgACkpKdBqta6OjYhowEbTHLikBJ6Tk4OWlhY8/fTTePjhh9Hc3MzdCIloROIUyhXq6+vxwQcf2M4jIyMxf/58lwVFRDRYEh5tUQxJFfhtt92GI0eO2M7/97//ITw83GVBERENlgVC8iF3kirwo0ePYtGiRZgyZQoA4Pvvv8e0adMQHx8PANi3b5/rIiQiGgAlTI1IJSmBb9682dVxEBE5hTOnUA4fPoyXXnoJVqsVycnJeOKJJ+y+N5lMyMnJwdGjRzF+/HgUFBQgKCgIRqMRGRkZ+Oqrr6DX65Gbm2v7zZIlS3DmzBlYLBbceeedWLFiBdRqNd544w3885//xIQJEwAAy5Ytw+9//3uH8UlK4FOnTh3ouImI3MJZFbjFYkFeXh62bdsGjUaDpKQk6HQ6hIWF2doUFRXB398fhw4dQnl5OfLz87Fu3Tp4e3sjMzMT9fX1qK+vt+u3sLAQvr6+EEIgIyMDBw4cQFxcHABg8eLFWLJkieQYJc2BExHJhbOWEdbV1SEkJATBwcHw8vJCXFwcqqqq7NpUV1fbdmqNjY1FTU0NhBDw8fHB7Nmz4e3t3adfX19fAEBvby/MZjNUKtWgx8oETkSK4qwXOhgMBkyaNMl2rtFo+rwHwWAwYPLkyQAAT09P+Pn5wWg09hvjkiVLMGfOHIwbNw6xsbG2z3ft2oX4+Hj8+c9/xoULF/rthwmciBRFDuvAt2zZgk8++QQmkwmffvopACA1NRWHDh1CaWkprr/+erzyyiv99sMETkSK4qwErtFocPr0adu5wWCARqPp06atrQ3A5SmRzs5OBAYGSorT29sb0dHRtmmZiRMnQq1Ww8PDA8nJyfjyyy/77YMJnIgURQgh+XAkIiICjY2NaG5uhslkQnl5OXQ6nV0bnU6HkpISAEBFRQUiIyMdzml3d3ejvb0dwOWE/+GHH+Kmm24CANvnAFBZWYnp06f3O1ZJq1CIiOTCWVMjnp6eyM3NxdKlS2GxWLBw4UJMnz4dhYWFCA8PR3R0NJKSkpCdnY2YmBgEBASgoKDA9nudToeuri6YzWZUVlZi69atGD9+PNLT02EymSCEwK9//WssWrQIALB27VqcOHECwOWVf3l5ef3GKOmVakPBV6oRkVTOeKXaXVN+J7nt/31/eMjXcydW4ESkKBYxejaUZQInIkUZTZtZMYETkaJwLxQiIplSwosapGICJyJFsXIKhYhInkZTBT7oB3nOnDnjzDiIiJzCIqySD7kbdAL/61//6sw4iIicwiqE5EPuBj2FsmnTJmfGQUTkFKNpCoVz4ESkKEqorKViAiciRWEFTkQkUxZhcXcIw4YJnIgUhY/SExHJFB+lJyKSKVbgREQyxVUoREQyxVUoREQypYRH5KViAiciReEcOBGRTHEOnIhIpliBExHJFNeBExHJFCtwIiKZ4ioUIiKZ4k1MIiKZ4hQKEZFM8UlMIiKZYgVORCRTo2kOXCVG0x9XREQK4uHuAIiIaHCYwImIZIoJnIhIppjAiYhkigmciEimmMCJiGSKCZyISKYUlcAXLVrk7hAka2lpwQMPPCC5fWVlJRoaGlwY0dAMdDxK8tZbb+HSpUu28w0bNrgxGhpNFJXAd+/e7e4QXGakJ/Ch6O3tdXg+0u3YscMugW/cuHHAfVgsFmeGRKOEoh6l12q1qK2tdXcYklksFjz//POora2FRqPB+vXr8f777+Pdd9+F2WxGSEgIXnvtNRw/fhzV1dX47LPP8I9//ANvvPEGAGDVqlUwGo0YM2YMXnzxRYSGhspiPGPHjsVzzz0HLy8vHD9+HLNmzYKvry+amprQ3NyMKVOmwGAw4Pnnn8ett94KAEhNTcWKFSswY8YMl4+jpaUFS5cuxcyZM3Hs2DFMnz4dr776Ko4cOYJXX30VFosF4eHhWLVqFXbv3o329nY8+uijGD9+PO644w78+OOPSExMRFhYGF5//XWUlpZi586dMJvNuOOOO7BixQqo1WpotVqkpKTgP//5D3JzczF79myXj40URijIr371K3eHIFlzc7O49dZbxbFjx4QQQmRkZIi9e/eKc+fO2dr87W9/Ezt27BBCCPHss8+K/fv327575JFHxKlTp4QQQhw5ckSkpaUNX/C/YDDjeeKJJ0Rvb68QQoi///3vQq/Xi0uXLgkhhCguLharV68WQghx8uRJodfrh3UsN998s/j888+FEEI899xz4s033xS/+93vxMmTJ4UQQmRnZ4tt27YJIYSYO3eu6OjosP3+5/8dNjQ0iCeffFKYTCYhhBArVqwQJSUlQgghbr75ZlFeXj4cQyKFUlQFLjdBQUG2CnPmzJlobW1FfX091q1bh87OTnR3d+O3v/1tn991d3ejtrYWmZmZts9MJtOwxX01Ax3PvHnzoFarbec6nQ5jxoyxfbd+/Xrk5ORgz549ePDBB4d1LJMnT8add94JAEhISMD69esRFBSEadOmAQD0ej127dqFxYsXO+ynpqYGX331FZKSkgAAP/74I6699loAgFqtRmxsrOsGQYrHBO5GXl5etr9Xq9Xo6enBc889h/Xr12PGjBkoLi7GZ5991ud3Qgj4+/ujtLR0OMPt10DHM3bsWLvf//x87NixmDNnDqqqqrB//34UFxe7fgA/o1Kp7M79/f1x/vz5AfcjhIBer8fy5cv7fOft7W33BxjRQCnqJqYSdHd347rrroPZbMa+fftsn48bNw7d3d0AAF9fXwQFBWH//v0ALieJEydOuCXe/lxtPFIkJydj9erViIiIQEBAgIsi/GXff/+97X5KWVkZwsPD0draiu+++w4AUFpairvuuguA/b8bAPD09ITZbAYAREVFoaKiAh0dHQCA8+fPo7W1dTiHQgrGBD7CZGZmIjk5Gampqbjppptsn8+fPx9btmzBggUL0NTUhLVr1+K9995DQkIC4uLiUFlZ6caor+5q45EiPDwcvr6+wz59AgDTpk3Drl27cP/99+OHH37A4sWLsWbNGmRmZiI+Ph4qlQqpqakAgIceeghLly5FWlqa7TwhIQHLly9HWFgYsrKy8PjjjyM+Ph6PP/44zpw5M+zjGYo//vGPMBgM7g6DfgH3A6cRy2Aw4JFHHsH+/fvh4TF8tUZLSwueeuoplJWVDds1iQaDFTiNSHv37sVDDz2ErKysYU3eRHLCCpyISKZY2hARyRQTOBGRTDGBExHJFBM4EZFMMYETEcnU/wNJJAYGqMEj8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot using Seaborn\n",
    "sample_id = 10\n",
    "\n",
    "\n",
    "ax = sns.heatmap(get_attention(A, [va_x[i] for i in idx], sample_id))\n",
    "print('label: {}, predicted: {}'.format(result.label[sample_id], result.pred_sa[sample_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1.]\n",
       "<NDArray 50 @gpu(0)>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1.]\n",
       "<NDArray 50 @gpu(0)>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1.]\n",
       "<NDArray 50 @gpu(0)>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.sum(A[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6,\n",
       "  2,\n",
       "  135,\n",
       "  27,\n",
       "  11,\n",
       "  13,\n",
       "  17,\n",
       "  22,\n",
       "  7,\n",
       "  92,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [11,\n",
       "  13,\n",
       "  19,\n",
       "  33,\n",
       "  22,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  16,\n",
       "  11,\n",
       "  13,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [20,\n",
       "  21,\n",
       "  54,\n",
       "  17,\n",
       "  338,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [263,\n",
       "  2,\n",
       "  59,\n",
       "  11,\n",
       "  13,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [34,\n",
       "  2,\n",
       "  303,\n",
       "  96,\n",
       "  3,\n",
       "  156,\n",
       "  5,\n",
       "  304,\n",
       "  26,\n",
       "  220,\n",
       "  3,\n",
       "  2,\n",
       "  58,\n",
       "  305,\n",
       "  38,\n",
       "  73,\n",
       "  37,\n",
       "  2,\n",
       "  306,\n",
       "  5,\n",
       "  26,\n",
       "  11,\n",
       "  13,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  16,\n",
       "  5,\n",
       "  8,\n",
       "  14,\n",
       "  82,\n",
       "  74,\n",
       "  42,\n",
       "  113,\n",
       "  253,\n",
       "  27,\n",
       "  34,\n",
       "  36,\n",
       "  18,\n",
       "  36,\n",
       "  101,\n",
       "  3,\n",
       "  105,\n",
       "  254,\n",
       "  84,\n",
       "  5,\n",
       "  255,\n",
       "  3,\n",
       "  256,\n",
       "  257,\n",
       "  3,\n",
       "  5,\n",
       "  258,\n",
       "  259,\n",
       "  3,\n",
       "  152,\n",
       "  15,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [8,\n",
       "  14,\n",
       "  17,\n",
       "  22,\n",
       "  2,\n",
       "  109,\n",
       "  66,\n",
       "  196,\n",
       "  74,\n",
       "  173,\n",
       "  176,\n",
       "  251,\n",
       "  7,\n",
       "  92,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [11,\n",
       "  13,\n",
       "  17,\n",
       "  86,\n",
       "  226,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  60,\n",
       "  25,\n",
       "  46,\n",
       "  96,\n",
       "  29,\n",
       "  2,\n",
       "  16,\n",
       "  8,\n",
       "  14,\n",
       "  3,\n",
       "  6,\n",
       "  2,\n",
       "  39,\n",
       "  60,\n",
       "  18,\n",
       "  202,\n",
       "  187,\n",
       "  76,\n",
       "  182,\n",
       "  24,\n",
       "  252,\n",
       "  3,\n",
       "  44,\n",
       "  24,\n",
       "  17,\n",
       "  126,\n",
       "  33,\n",
       "  37,\n",
       "  185,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  16,\n",
       "  11,\n",
       "  13,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [132,\n",
       "  28,\n",
       "  23,\n",
       "  3,\n",
       "  260,\n",
       "  2,\n",
       "  130,\n",
       "  261,\n",
       "  6,\n",
       "  2,\n",
       "  16,\n",
       "  11,\n",
       "  13,\n",
       "  262,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [132,\n",
       "  28,\n",
       "  23,\n",
       "  3,\n",
       "  260,\n",
       "  2,\n",
       "  130,\n",
       "  261,\n",
       "  6,\n",
       "  2,\n",
       "  16,\n",
       "  11,\n",
       "  13,\n",
       "  262,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  31,\n",
       "  8,\n",
       "  14,\n",
       "  3,\n",
       "  27,\n",
       "  199,\n",
       "  296,\n",
       "  224,\n",
       "  18,\n",
       "  86,\n",
       "  297,\n",
       "  15,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [10,\n",
       "  9,\n",
       "  12,\n",
       "  151,\n",
       "  79,\n",
       "  3,\n",
       "  79,\n",
       "  3,\n",
       "  43,\n",
       "  3,\n",
       "  43,\n",
       "  3,\n",
       "  93,\n",
       "  3,\n",
       "  63,\n",
       "  3,\n",
       "  93,\n",
       "  3,\n",
       "  63,\n",
       "  3,\n",
       "  205,\n",
       "  3,\n",
       "  18,\n",
       "  3,\n",
       "  52,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [2,\n",
       "  31,\n",
       "  8,\n",
       "  14,\n",
       "  3,\n",
       "  27,\n",
       "  199,\n",
       "  296,\n",
       "  224,\n",
       "  18,\n",
       "  86,\n",
       "  297,\n",
       "  15,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[va_x[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'c']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in aa if x is not 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = pd.DataFrame(A[0].asnumpy(), index = ['a' + str(i) for i in range(50)], columns = ['b' + str(i) for i in range(50)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ['a0', 'a1']\n",
    "col = ['b0', 'b1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a0</th>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>0.020484</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          b0    b1\n",
       "a0  0.012424  0.02\n",
       "a1  0.020484  0.02"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.loc[idx][col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-7ec13776e2c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mva_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_id' is not defined"
     ]
    }
   ],
   "source": [
    "att = get_attention(A, [va_x[i] for i in idx], sample_id)\n",
    "type(att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "* Only 33 comments are mis-classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result['pred_rn'] != result['label']].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
